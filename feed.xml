<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://gstechschulte.github.io/cached-projects/feed.xml" rel="self" type="application/atom+xml" /><link href="https://gstechschulte.github.io/cached-projects/" rel="alternate" type="text/html" /><updated>2022-06-24T00:18:36-05:00</updated><id>https://gstechschulte.github.io/cached-projects/feed.xml</id><title type="html">Cached</title><subtitle>Ideas, thoughts, and projects</subtitle><entry><title type="html">ELBO</title><link href="https://gstechschulte.github.io/cached-projects/probability/optimization/2022/06/23/ELBO.html" rel="alternate" type="text/html" title="ELBO" /><published>2022-06-23T00:00:00-05:00</published><updated>2022-06-23T00:00:00-05:00</updated><id>https://gstechschulte.github.io/cached-projects/probability/optimization/2022/06/23/ELBO</id><author><name></name></author><category term="probability" /><category term="optimization" /><summary type="html"><![CDATA[If we have the joint $p(x, z)$ where $x$ is some observed data, the goal is to perform inference: given what we have observed, what can we infer about the latent states?, i.e., we want the posterior.]]></summary></entry><entry><title type="html">One is a Crowd</title><link href="https://gstechschulte.github.io/cached-projects/probability/reading/2022/06/21/Judgements-Probability.html" rel="alternate" type="text/html" title="One is a Crowd" /><published>2022-06-21T00:00:00-05:00</published><updated>2022-06-21T00:00:00-05:00</updated><id>https://gstechschulte.github.io/cached-projects/probability/reading/2022/06/21/Judgements-Probability</id><author><name></name></author><category term="probability" /><category term="reading" /><summary type="html"><![CDATA[In the book, Noise: A Flaw in Human Judgement, the authors point out a study conducted by Edward Val and Harold Pashler in which the subjects answer a question, and then subsequently, are asked to answer the same question again. The subjects did not know they would have to answer the question twice. Val and Pashler’s hypothesis was that the average of the two answers would be more accurate than either of the two answers on their own. The researchers who conducted the study drew inspiration from the wisdom of the crowds effect—averaging independent judgements of different people generally improves accuracy.]]></summary></entry><entry><title type="html">Bayesian Modeling and Computation in Python</title><link href="https://gstechschulte.github.io/cached-projects/jupyter/2022/06/14/bmcp-ch-3.html" rel="alternate" type="text/html" title="Bayesian Modeling and Computation in Python" /><published>2022-06-14T00:00:00-05:00</published><updated>2022-06-14T00:00:00-05:00</updated><id>https://gstechschulte.github.io/cached-projects/jupyter/2022/06/14/bmcp-ch-3</id><author><name></name></author><category term="jupyter" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Probabilistic Prediction Problems - Part 1</title><link href="https://gstechschulte.github.io/cached-projects/probability/2022/05/31/Probabilistic-Predicion-Problems-Part-1.html" rel="alternate" type="text/html" title="Probabilistic Prediction Problems - Part 1" /><published>2022-05-31T00:00:00-05:00</published><updated>2022-05-31T00:00:00-05:00</updated><id>https://gstechschulte.github.io/cached-projects/probability/2022/05/31/Probabilistic-Predicion-Problems-Part-1</id><author><name></name></author><category term="probability" /><summary type="html"><![CDATA[Part one deals with why parameters (or latent variables) are problematic and common loss functions for comparing two probability distributions.]]></summary></entry><entry><title type="html">Textbooks Have Gotten Good, Like Really Good</title><link href="https://gstechschulte.github.io/cached-projects/2021/09/14/Textbooks-Have-Gotten-Good,-Like-Really-Good.html" rel="alternate" type="text/html" title="Textbooks Have Gotten Good, Like Really Good" /><published>2021-09-14T00:00:00-05:00</published><updated>2021-09-14T00:00:00-05:00</updated><id>https://gstechschulte.github.io/cached-projects/2021/09/14/Textbooks-Have-Gotten-Good,-Like-Really-Good</id><author><name></name></author><summary type="html"><![CDATA[In a recent interview, they presented the problem they were facing and asked about the methods I would use to go about solving it. I started off with the heuristics behind the method (Bayesian inference if you are curious) and continued into some of the more detailed advantages and disadvantages behind why I would choose this method. I think they were a bit surprised about this as my original background is in economics, which is traditionally a domain that employs frequentist based methodologies. This led the interviewers to asking, “It seems you are quite familiar with Bayesian statistics and given your background, how did you come to using Bayesian methods within your projects?”. To which I responded, “I first read about the concept in Thinking Fast and Slow by Daniel Kahneman and became deeply intrigued, so I read a few textbooks about Bayesian statistics and Bayesian methods in machine learning.” The interviewers responses, “You read textbooks?”.]]></summary></entry></feed>